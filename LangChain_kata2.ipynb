{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRyrrs+w8JVvBvTj9ei6Va",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gireesheruvaram/LLM-Beginer/blob/Langchain-kata2branch/LangChain_kata2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SsbL583b0At",
        "outputId": "b624e55f-7158-466f-a5d9-2ce4dd760ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.27.8) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.27.8) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.27.8) (3.11.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.27.8) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.27.8) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.27.8) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.27.8) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (1.18.3)\n",
            "Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.27.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzetrtbPdYSa",
        "outputId": "9951c7f8-4ee3-4400-9073-43b6f5be2c4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.44)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.13)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.19 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_WUODaZdep8",
        "outputId": "9185315f-b6ab-4404-d061-cc14fdb463b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('LLma')\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "5BbNy57WdiMX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "# Get the current date\n",
        "current_date = datetime.datetime.now().date()\n",
        "\n",
        "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
        "target_date = datetime.date(2024, 6, 12)\n",
        "\n",
        "# Set the model variable based on the current date\n",
        "if current_date > target_date:\n",
        "    llm_model = \"gpt-3.5-turbo-1106\"\n",
        "else:\n",
        "    llm_model = \"gpt-3.5-turbo-0301\""
      ],
      "metadata": {
        "id": "J5ja5iVVdv4J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Langchain components\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "# Initialize the language model with the API key\n",
        "llm = ChatOpenAI(\n",
        "    model_name=llm_model,\n",
        "    temperature=0.7,  # Adjust creativity level\n",
        "    openai_api_key=openai.api_key  # Use the dynamically retrieved API key\n",
        ")\n",
        "\n",
        "# Set up memory for context-aware conversation\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Create a conversation chain\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOVv3_DQd1PK",
        "outputId": "fcecada2-e439-4847-c4c8-0136781f8da2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-1cae08f96c8c>:8: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(\n",
            "<ipython-input-10-1cae08f96c8c>:15: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n",
            "<ipython-input-10-1cae08f96c8c>:18: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation = ConversationChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "# Improved prompt template for detailed step-by-step reasoning\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=(\n",
        "        \"You are a helpful assistant who carefully explains your reasoning step-by-step before providing the final answer. \"\n",
        "        \"For the given query, break the problem down into clear steps, explaining each part thoroughly. \"\n",
        "        \"After the step-by-step explanation, conclude with the final answer.\\n\\n\"\n",
        "        \"Query: {query}\\n\\n\"\n",
        "        \"Step-by-step explanation:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create the chain with the improved prompt\n",
        "cot_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# Example queries to test step-by-step reasoning\n",
        "queries = [\n",
        "    \"What is the result of 25 multiplied by 4, and then add 7?\",\n",
        "    \"If all cats are mammals and some mammals are dogs, are all cats dogs?\",\n",
        "    \"What is the next number in the sequence: 2, 4, 8, 16?\"\n",
        "]\n",
        "\n",
        "# Process each query through the chain\n",
        "for query in queries:\n",
        "    response = cot_chain.run(query)\n",
        "    print(f\"Query: {query}\\nResponse:\\n{response}\\n{'-'*50}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9iiErSwqv7Q",
        "outputId": "b23a4cd9-1958-4e56-ea70-b575f1e1db6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-48b2e0317421>:16: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  cot_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
            "<ipython-input-11-48b2e0317421>:27: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = cot_chain.run(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is the result of 25 multiplied by 4, and then add 7?\n",
            "Response:\n",
            "Step 1: Multiply 25 by 4\n",
            "To find the result of 25 multiplied by 4, simply multiply 25 by 4:\n",
            "25 x 4 = 100\n",
            "\n",
            "Step 2: Add 7 to the result\n",
            "After multiplying 25 by 4, the next step is to add 7 to the result:\n",
            "100 + 7 = 107\n",
            "\n",
            "Final answer: The result of 25 multiplied by 4, and then adding 7 is 107.\n",
            "--------------------------------------------------\n",
            "\n",
            "Query: If all cats are mammals and some mammals are dogs, are all cats dogs?\n",
            "Response:\n",
            "1. First, we need to understand the relationships between the different animals mentioned in the query. It is stated that all cats are mammals, which means that every cat is a mammal. This forms a universal statement about the relationship between cats and mammals.\n",
            "\n",
            "2. Next, it is also stated that some mammals are dogs. This means that there is at least one mammal that is a dog, but not necessarily all mammals are dogs. This forms an existential statement about the relationship between mammals and dogs.\n",
            "\n",
            "3. Now, based on the given information, we can conclude that all cats are mammals and some mammals are dogs. However, this does not mean that all cats are dogs. \n",
            "\n",
            "Final answer: No, all cats are not dogs. The given information only establishes that all cats are mammals and that some mammals are dogs, but it does not provide evidence to conclude that all cats are dogs.\n",
            "--------------------------------------------------\n",
            "\n",
            "Query: What is the next number in the sequence: 2, 4, 8, 16?\n",
            "Response:\n",
            "1. First, we need to identify the pattern in the given sequence. Looking at the numbers, we can see that each number is double the previous number.\n",
            "\n",
            "2. Starting with 2, the next number in the sequence is obtained by multiplying 2 by 2, which equals 4.\n",
            "\n",
            "3. Similarly, 4 is doubled to get 8, and 8 is doubled to get 16.\n",
            "\n",
            "4. Therefore, following the same pattern, the next number in the sequence is obtained by doubling 16, which equals 32.\n",
            "\n",
            "Final answer: The next number in the sequence is 32.\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain # Import both PromptTemplate and LLMChain\n",
        "\n",
        "# Define a prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=(\n",
        "        \"You are a helpful assistant skilled in explaining your reasoning clearly and step-by-step. \"\n",
        "        \"For the given query, provide an explanation of your thought process before giving the final answer. \"\n",
        "        \"Query: {query}\\n\"\n",
        "        \"Explanation of reasoning:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Now you can use LLMChain since it has been imported\n",
        "cot_chain = LLMChain(llm=llm, prompt=prompt_template)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaQMtj79d5Ea",
        "outputId": "49e0521c-27ad-4277-bad5-acaf2a5e7877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-71ac0989e21a>:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  cot_chain = LLMChain(llm=llm, prompt=prompt_template)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"What is the result of 25 multiplied by 4, and then add 7?\",\n",
        "    \"If all cats are mammals and some mammals are dogs, are all cats dogs?\",\n",
        "    \"What is the next number in the sequence: 2, 4, 8, 16?\"\n",
        "]\n",
        "\n",
        "# Process each query through the chain\n",
        "for query in queries:\n",
        "    response = cot_chain.run(query)\n",
        "    print(f\"Query: {query}\\nResponse:\\n{response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4qTtpQZevdc",
        "outputId": "47f97a44-5e5c-4365-c7a1-dddd41ad5717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-4dbeb40a9470>:9: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = cot_chain.run(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is the result of 25 multiplied by 4, and then add 7?\n",
            "Response:\n",
            "To find the result of 25 multiplied by 4, we first need to perform the multiplication operation. So, 25 multiplied by 4 equals 100. Then, we are asked to add 7 to this result. Adding 7 to 100 gives us a final result of 107. Therefore, the result of 25 multiplied by 4 and then adding 7 is 107.\n",
            "\n",
            "Query: If all cats are mammals and some mammals are dogs, are all cats dogs?\n",
            "Response:\n",
            "First, let's break down the information given in the query. It states that all cats are mammals, and that some mammals are dogs.\n",
            "\n",
            "Based on this information, we can conclude that all cats are indeed mammals, and that some mammals are dogs. However, this does not necessarily mean that all cats are dogs.\n",
            "\n",
            "In logic, the statement \"All A are B\" does not necessarily mean \"All B are A.\" In this case, just because all cats are mammals and some mammals are dogs, it does not mean that all cats are dogs.\n",
            "\n",
            "Therefore, the final answer is: No, all cats are not dogs.\n",
            "\n",
            "Query: What is the next number in the sequence: 2, 4, 8, 16?\n",
            "Response:\n",
            "To find the next number in the sequence, we need to look for a pattern or rule that governs the progression from one number to the next. In this sequence, it appears that each number is being multiplied by 2 to get the next number. \n",
            "\n",
            "Starting with 2, when multiplied by 2, we get 4. \n",
            "Then, when 4 is multiplied by 2, we get 8. \n",
            "Following the same pattern, when 8 is multiplied by 2, we get 16. \n",
            "\n",
            "So, the next number in the sequence would be 16 multiplied by 2, which equals 32. \n",
            "\n",
            "Therefore, the next number in the sequence is 32.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}