{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVkFN3XndRT0y6fDljVfTn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gireesheruvaram/LLM-Beginer/blob/LLMadv-kata3-problem1/LLM_adv_kata3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CDFVmT2BA058"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import emoji\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHhGUsyb-rza",
        "outputId": "b7140554-3557-469b-cb80-cf327cea0650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the set of stop words for English\n",
        "STOP_WORDS = set(stopwords.words('english'))\n",
        "def replace_emoji_with_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Replaces emojis in the text with their descriptive names.\n",
        "    \"\"\"\n",
        "    return emoji.demojize(text, delimiters=(\" \", \" \"))"
      ],
      "metadata": {
        "id": "e5bAjF7M-weL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Text Normalization\n",
        "def normalize_text(comment: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalizes the given text by:\n",
        "    - Converting all characters to lowercase.\n",
        "    - Removing punctuation except exclamation points (!) and question marks (?).\n",
        "    - Replacing emojis with descriptive text dynamically.\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    comment = comment.lower()\n",
        "\n",
        "    # Replace emojis with descriptive text\n",
        "    comment = replace_emoji_with_text(comment)\n",
        "\n",
        "    # Remove punctuation except ! and ?\n",
        "    comment = re.sub(r\"[^\\w\\s!?]\", \"\", comment)\n",
        "\n",
        "    return comment"
      ],
      "metadata": {
        "id": "ob9kBs65-4Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #2. Tokenization\n",
        "def tokenize_text(normalized_text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Splits the normalized text into individual words (tokens).\n",
        "    \"\"\"\n",
        "    return normalized_text.split()\n",
        "\n",
        "# 3. Stop Word Removal\n",
        "def remove_stop_words(tokens: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Removes common stop words from the list of tokens.\n",
        "    \"\"\"\n",
        "    return [token for token in tokens if token not in STOP_WORDS]"
      ],
      "metadata": {
        "id": "WTj-nBSX--vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    comment = \"The movie was AMAZING! üòä‚ù§Ô∏è But it had some boring scenes. üò¢üòÇ\"\n",
        "\n",
        "    # Step 1: Normalize text\n",
        "    normalized = normalize_text(comment)\n",
        "    print(\"Normalized Text:\", normalized)\n",
        "\n",
        "    # Step 2: Tokenize text\n",
        "    tokens = tokenize_text(normalized)\n",
        "    print(\"Tokens:\", tokens)\n",
        "\n",
        "    # Step 3: Remove stop words\n",
        "    filtered_tokens = remove_stop_words(tokens)\n",
        "    print(\"Filtered Tokens:\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0UjcNdQ_Eo9",
        "outputId": "397c2a78-8bbd-4d7a-b6b0-13d4e9610511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Text: the movie was amazing!  smiling_face_with_smiling_eyes  red_heart  but it had some boring scenes  crying_face  face_with_tears_of_joy \n",
            "Tokens: ['the', 'movie', 'was', 'amazing!', 'smiling_face_with_smiling_eyes', 'red_heart', 'but', 'it', 'had', 'some', 'boring', 'scenes', 'crying_face', 'face_with_tears_of_joy']\n",
            "Filtered Tokens: ['movie', 'amazing!', 'smiling_face_with_smiling_eyes', 'red_heart', 'boring', 'scenes', 'crying_face', 'face_with_tears_of_joy']\n"
          ]
        }
      ]
    }
  ]
}